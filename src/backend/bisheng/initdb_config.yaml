knowledges:
  unstructured_api_url: ""  # 毕昇非结构化数据解析服务地址，提供包括OCR文字识别、表格识别、版式分析等能力。非必填，溯源必填
  embeddings: # 配置知识库的embedding服务，以下示例填写了两类embedding服务的配置方法，第一个是openai的embedding模型服务的配置方法，第二个是本地部署的embedding模型服务的配置方法，如果有多个可以添加多个
    text-embedding-ada-002: # 知识库下拉框中显示的embedding模型的名称，可自定义
      openai_api_base: "https://api.openai.com/v1"
      openai_proxy: "" # 如果是自己代理的服务地址，则填在这里
      openai_api_key: "" # 私有的，openai账号的key
      # deployment: ""  # azure 部署需要
      # openai_api_type: ""    # azure api_type
      # openai_api_version: ""  # azure api_version
    embedding-host: # 知识库下拉框中显示的embedding模型的名称，可自定义
      host_base_url: "" # 在模型管理页面中已上线的embedding服务的地址
      model: "" # 在模型管理页面中已上线的embedding模型的名称
    # custom-embedding:
    #   component: custom

  vectorstores:
    # Milvus 最低要求cpu 4C 8G 推荐4C 16G
    Milvus: # 如果需要切换其他vectordb，确保其他服务已经启动，然后配置对应参数
      connection_args: { 'host': 'milvus', 'port': '19530', 'user': '', 'password': '', 'secure': False }
      # partiton-key model, 用于分区的字段，如果不配置默认True， 分区后，新的partiton不会新建collection，可以通过增加suffix强制增加collection
      is_partition: False
      partition_suffix: 1
    # 可选配置，有些类型的场景使用ES可以提高召回效果
    ElasticKeywordsSearch:
      elasticsearch_url: 'http://elasticsearch:9200'
      ssl_verify: "{'basic_auth': ('elastic', 'password')}"
      #   ssl_verify: "{'ca_certs': False, 'basic_auth': ('elastic', 'F94h5JtdQn6EQB-G9Hjv'), 'verify_certs': False}"
  minio: # 如果要支持溯源功能，由于溯源会展示源文件，必须配置 oss 存储
    SCHEMA: false         # 是否支持 https
    CERT_CHECK: false         # 是否校验 http证书
    MINIO_ENDPOINT: "minio:9000"       # 这个地址用来写请求, 使用同一个docker-compose 启动，能通过容器名访问
    MINIO_SHAREPOIN: "minio:9000"      # 确保和nginx的代理地址一致。同一个docker-compose启动可以直接使用默认值
    MINIO_ACCESS_KEY: "minioadmin"
    MINIO_SECRET_KEY: "minioadmin"
  #

default_llm:
  # 全局配置大模型    
  model: "" # 在模型管理页面中已上线的大模型服务的名称
  host_base_url: "" # 在模型管理页面中已上线的大模型服务的地址

llm_request:
  # 模型访问的超时配置
  request_timeout: 600
  max_retries: 1
  stream: true


# 是否需要验证码
use_captcha:
  True

# 聊天对话框配置
dialog_tips:
  "内容由AI生成，仅供参考！"

env:
  # 聊天窗口支持快捷搜索的搜索引擎
  # dialog_quick_search: http://www.baidu.com/s?wd=
  # 可配置与http不一致的websocket地址
  # websocket_url: 192.168.106.120:3003
  office_url: http://IP:8701 # office 组件访问地址，需要浏览器能直接访问

# 智能助手相关配置
gpts:
  agent_executor:
    # 默认agent的executor, 如果模型里有配置优先用模型的
    type: 'get_openai_functions_agent_executor'
    interrupt_before_action: False
    recursion_limit: 50
  #  助手可选大模型列表，第一个为默认模型
  llms:
    - type: 'ChatOpenAI'
      model_name: 'gpt-4-0125-preview'
      # model: 'gpt-3.5-turbo-0125'
      openai_api_key: ''
      openai_proxy: 'http://118.195.232.223:39995'
      temperature: 0.3
    - type: 'CustomLLMChat'
      model_name: 'Qwen-1_8B-Chat'
      host_base_url: 'http://192.168.106.12:9001/v2.1/models/Qwen-1_8B-Chat/infer'
      temperature: 0.3
      agent_executor_type: 'get_qwen_local_functions_agent_executor'
